{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a34b4fe8-8bad-4009-8708-345d29320ed5",
   "metadata": {},
   "source": [
    "## Objectives\n",
    "\n",
    "1. Use SerpAPI to query the web\n",
    "2. Extract content from top 3-5 pages using newspaper3k\n",
    "3. Summarize relevant info for prompt context use a local LLM\n",
    "4. store recent ssearch results with timestamps for reuse\n",
    "\n",
    "### Dependencies\n",
    "\n",
    "- serpapi, newspaper, readability-lxml, beautifulsoup4, lxml, transformers, google-search-results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66dee976-4137-4d4f-ac5e-57249fb24978",
   "metadata": {},
   "source": [
    "## Code\n",
    "\n",
    "### Library Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "4fa7fbea-e857-41b8-9666-30799d730abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing libraries\n",
    "import os\n",
    "import json\n",
    "import requests\n",
    "import sqlite3\n",
    "from serpapi import GoogleSearch\n",
    "from newspaper import Article\n",
    "from bs4 import BeautifulSoup\n",
    "from readability import Document\n",
    "from datetime import datetime, timedelta\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "590b4f4e-dc5f-41c2-8b8f-e524e5c76115",
   "metadata": {},
   "source": [
    "### Extracting Top URLs from Google\n",
    "\n",
    "We use SerpAPI to perform a Google search using the query. Default is to collect the top five search results. We also test the function below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "74d383f7-2a72-45b9-bd48-a81d916befab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#API key from SerpAPI\n",
    "SERPAPI_KEY = \"c109882a3ac9a1a7728552909b5e962a34ba1201be40921588a932f1e8aeb84e\"\n",
    "\n",
    "def search_google_serpapi(query,api_key,num_results=5):\n",
    "    \"\"\"\n",
    "    Uses SerpAPI to perform a Google search and return top result URLs.\n",
    "    Parameters:\n",
    "    - query (str): the search query\n",
    "    - api_key (str): the SerpAPI key\n",
    "    - num_results (int): # of URLs to return (default is 5)\n",
    "    Returns:\n",
    "    - List[str]: List of top URLs from organic search results.\n",
    "    \"\"\"\n",
    "    \n",
    "    #Setting parameters for the SerpAPI request\n",
    "    params={\n",
    "        \"engine\":\"google\",      #use Google engine\n",
    "        \"q\":query,              #search query\n",
    "        \"api_key\":api_key,      #SerpAPI key\n",
    "        \"num\":num_results       #number of results to fetch\n",
    "    }\n",
    "\n",
    "    #Making the search request using the SerpAPI client\n",
    "    search=GoogleSearch(params)\n",
    "    results=search.get_dict()\n",
    "\n",
    "    #Checking if organic results are present in the response\n",
    "    if \"organic_results\" not in results:\n",
    "        print(\"No search results returned.\")\n",
    "        return []\n",
    "\n",
    "    #List to store the top URLs\n",
    "    urls=[]\n",
    "\n",
    "    #Looping through the top organic results and collecting URLs\n",
    "    for result in results[\"organic_results\"][:num_results]:\n",
    "        url=result.get(\"link\")\n",
    "        if url:\n",
    "            urls.append(url)\n",
    "\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a3d32bf7-0f63-42a8-a6fb-18a6e99d73fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/deployment-plan-compliance-policies', 'https://learn.microsoft.com/en-us/intune/intune-service/protect/device-compliance-get-started']\n"
     ]
    }
   ],
   "source": [
    "#Example search\n",
    "query=\"Best practices for Microsoft Intune device compliance\"\n",
    "top_urls=search_google_serpapi(query,SERPAPI_KEY,3)\n",
    "print(top_urls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b4437-3177-4a66-bf9c-6c764ef3d991",
   "metadata": {},
   "source": [
    "### Extracting Content from URLs\n",
    "\n",
    "We design a function that tries to extract article text with `newspaper3k`. If it fails, it will try to use readability and BeautifulSoup. It will then return clean extracted text (or an empty string if nothing works). Function is tested below using the top URLs we found in the previous example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "020d9855-c330-44ab-8de8-da04ebff515b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_text(url):\n",
    "    \"\"\"\n",
    "    Extracts readable text content from a given URL.\n",
    "    Attempts to use newspaper3k first, then falls back to readability and BeautifulSoup\n",
    "    Parameters:\n",
    "    - url (str): the URL of the page to extract\n",
    "    Returns:\n",
    "    - str: extracted article/page text (empty string if failed)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        #Attempting to use newspaper3k first\n",
    "        article=Article(url)\n",
    "        article.download()\n",
    "        article.parse()\n",
    "        if article.text.strip():\n",
    "            return article.text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[newspaper3k] failed for {url}: {e}\")\n",
    "\n",
    "    try:\n",
    "        #Attempting fallback which is to use readability-lxml and BeautifulSoup\n",
    "        response=requests.get(url,timeout=10)\n",
    "        doc=Document(response.text)\n",
    "        html=doc.summary()  #Extracting main content HTML\n",
    "        soup=BeautifulSoup(html,\"html.parser\")\n",
    "        text=soup.get_text(separator=\"\\n\")\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        print(f\"[fallback] failed for {url}: {e}\")\n",
    "\n",
    "    return \"\"  #Returning empty string if all methods fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "295665fe-ed3e-41df-919a-5833fef8f6e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting from: https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/deployment-plan-compliance-policies\n",
      "Access to this page requires authorization. You can try changing directories .\n",
      "\n",
      "Access to this page requires authorization. You can try signing in or changing directories .\n",
      "\n",
      "Step 3 – Plan for compliance policies\n",
      "\n",
      "Previously, you set up your Intune subscription and created app protection policies. Next, plan for and configure device compliance settings and policies to help protect organizational data by requiring devices to meet requirements that you set.\n",
      "\n",
      "If you’re not yet familiar with compliance policies, see Compliance overview.\n",
      "\n",
      "This article applies to:\n",
      "\n",
      "Android Enterprise (Fully Managed, and Personally owned work profiles)\n",
      "\n",
      "Android Open-Source Project (AOSP)\n",
      "\n",
      "iOS/iPadOS\n",
      "\n",
      "Linux\n",
      "\n",
      "macOS\n",
      "\n",
      "Windows\n",
      "\n",
      "You deploy compliance policies to groups of devices or users. When deployed to users, any device the user signs into must then meet the policies requirements. Some common examples of compliance requirements include:\n",
      "\n",
      "Requiring a minimum operating system version.\n",
      "\n",
      "Use of a password or PIN tha\n",
      "Extracting from: https://learn.microsoft.com/en-us/intune/intune-service/protect/device-compliance-get-started\n",
      "Access to this page requires authorization. You can try changing directories .\n",
      "\n",
      "Access to this page requires authorization. You can try signing in or changing directories .\n",
      "\n",
      "Use compliance policies to set rules for devices you manage with Intune\n",
      "\n",
      "Microsoft Intune compliance policies are sets of rules and conditions that you use to evaluate the configuration of your managed devices. These policies can help you secure organizational data and resources from devices that don't meet those configuration requirements. Managed devices must satisfy the conditions you set in your policies to be considered compliant by Intune.\n",
      "\n",
      "If you also integrate the compliance results from your policies with Microsoft Entra Conditional Access, you can benefit from an extra layer of security. Conditional Access can enforce Microsoft Entra access controls based on a devices current compliance status to help ensure that only devices that are compliant are permitted to access corporate resources.\n",
      "\n",
      "Intune complian\n"
     ]
    }
   ],
   "source": [
    "#Example extracting text from one of our top search results in previous example\n",
    "for url in top_urls:\n",
    "    print(f\"Extracting from: {url}\")\n",
    "    text=extract_page_text(url)\n",
    "    print(text[:1000])  #Previewing first 1000 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0c7e5a6-0d48-4425-943c-47db3eb68119",
   "metadata": {},
   "source": [
    "### Summarizing Top Results\n",
    "\n",
    "For summarization, we have two options:\n",
    "\n",
    "1. LLM-based summarization is best for summarizing long documents with nuance, tone, or goal-aware prompts. Pros are that it provides high-quality, human-like summaries, can follow instructions, and is easy to use with Hugging Face or OpenAI APIs. Cons include that it requires GPU/cloud if using local models, may be slower, and has risk of hallucination.\n",
    "2. Embedding-based (vector similarity) is best for finding most relevant parts of documents. It's fast, scalable, and great for chunk retrieval. However, it's not a real summary, doesn’t rewrite text, and needs good chunking and query crafting.\n",
    "\n",
    "We will use a hybrid approach:\n",
    "\n",
    "- Use embeddings to filter or rank which chunks or articles are relevant\n",
    "- Then use an LLM to summarize the filtered/retrieved content into a clean paragraph and tailor it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "29450b08-fe7b-45d0-b10b-29f45b2f2f0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cpu\n"
     ]
    }
   ],
   "source": [
    "#Loading embedding model (same one used in during preprocessing of .docx files)\n",
    "embedding_model=SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "def rank_chunks_by_similarity(chunks,query,top_k=3):\n",
    "    \"\"\"\n",
    "    Returns top_k (default is 3) chunks most semantically similar to the query\n",
    "    \"\"\"\n",
    "    query_embedding=embedding_model.encode(query,convert_to_tensor=True)\n",
    "    chunk_embeddings=embedding_model.encode(chunks, convert_to_tensor=True)\n",
    "\n",
    "    #Computing similarity scores\n",
    "    similarities=util.pytorch_cos_sim(query_embedding,chunk_embeddings)[0]\n",
    "    top_indices=similarities.topk(k=top_k).indices\n",
    "\n",
    "    #Returning top ranked chunks\n",
    "    return [chunks[i] for i in top_indices]\n",
    "\n",
    "#Loading summarization pipeline (do this only once)\n",
    "summarizer=pipeline(\"summarization\",model=\"facebook/bart-large-cnn\")\n",
    "\n",
    "def summarize_text_with_llm(text,style_prompt=\"Summarize in plain English.\"):\n",
    "    \"\"\"\n",
    "    Uses a language model to summarize the text\n",
    "    \"\"\"\n",
    "    #Combining custom instructions with the extracted text\n",
    "    input_text = f\"{style_prompt}\\n\\n{text}\"\n",
    "    \n",
    "    #Truncating if too long\n",
    "    input_text=input_text[:1024]\n",
    "\n",
    "    summary=summarizer(input_text,max_length=150,min_length=40,do_sample=False)\n",
    "    return summary[0]['summary_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "88deebda-6bdf-4053-a5f6-30dfffec97d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use compliance policies to set rules for devices you manage with Intune. Conditional Access can enforce Microsoft Entra access controls based on a devices current compliance status to help ensure that only devices that are compliant are permitted to access corporate resources.\n"
     ]
    }
   ],
   "source": [
    "#Example workflow\n",
    "#1. Search and extract content\n",
    "urls=search_google_serpapi(query,SERPAPI_KEY)\n",
    "chunks=[extract_page_text(url) for url in urls]\n",
    "\n",
    "#2. Rank by similarity to query\n",
    "top_chunks=rank_chunks_by_similarity(chunks, query)\n",
    "\n",
    "#3. Summarize best content\n",
    "summary = summarize_text_with_llm(\"\\n\\n\".join(top_chunks),style_prompt=\"Summarize in plain English.\")\n",
    "\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8a521b-7ae9-4889-a04a-4982daaf5219",
   "metadata": {},
   "source": [
    "### Search Result Cache\n",
    "\n",
    "We implement a SQLite cache with 30-day expiration logic which gives us a robust, queryable, and scalable solution. We’ll store the query, result URLs, summary, and timestamp."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fa6b6db2-14cc-45e3-bc66-191edc3d007b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating or connecting to the SQLite database\n",
    "conn=sqlite3.connect(\"search_cache.db\")\n",
    "cursor=conn.cursor()\n",
    "\n",
    "#Creating the cache table if it doesn't exist\n",
    "cursor.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS search_cache (\n",
    "    query TEXT PRIMARY KEY,\n",
    "    urls TEXT,\n",
    "    summary TEXT,\n",
    "    timestamp TEXT\n",
    ")\n",
    "\"\"\")\n",
    "conn.commit()\n",
    "\n",
    "def is_cache_valid(timestamp_str,expiry_days=30):\n",
    "    \"\"\"\n",
    "    Check if cached timestamp is within expiry period\n",
    "    \"\"\"\n",
    "    timestamp=datetime.fromisoformat(timestamp_str)\n",
    "    return datetime.utcnow() - timestamp <= timedelta(days=expiry_days)\n",
    "\n",
    "def get_cached_result_sqlite(query):\n",
    "    \"\"\"\n",
    "    Return cached result if valid; otherwise None\n",
    "    \"\"\"\n",
    "    cursor.execute(\"SELECT urls, summary, timestamp FROM search_cache WHERE query = ?\", (query,))\n",
    "    row=cursor.fetchone()\n",
    "    if row:\n",
    "        urls, summary, timestamp=row\n",
    "        if is_cache_valid(timestamp):\n",
    "            return {\n",
    "                \"urls\":json.loads(urls),\n",
    "                \"summary\":summary,\n",
    "                \"timestamp\":timestamp\n",
    "            }\n",
    "        else:\n",
    "            print(\"Cache expired. Deleting old entry...\")\n",
    "            cursor.execute(\"DELETE FROM search_cache WHERE query = ?\", (query,))\n",
    "            conn.commit()\n",
    "    return None\n",
    "\n",
    "def store_result_in_cache_sqlite(query, urls, summary):\n",
    "    \"\"\"\n",
    "    Store new query results with timestamp\n",
    "    \"\"\"\n",
    "    timestamp=datetime.utcnow().isoformat()\n",
    "    cursor.execute(\"\"\"\n",
    "        INSERT OR REPLACE INTO search_cache (query, urls, summary, timestamp)\n",
    "        VALUES (?, ?, ?, ?)\n",
    "    \"\"\", (query, json.dumps(urls), summary, timestamp))\n",
    "    conn.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "33ea59ef-a77c-4008-96cb-649b19301ba8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded from cache:\n",
      "{\n",
      "  \"urls\": [\n",
      "    \"https://learn.microsoft.com/en-us/intune/intune-service/fundamentals/deployment-plan-compliance-policies\",\n",
      "    \"https://learn.microsoft.com/en-us/intune/intune-service/protect/device-compliance-get-started\",\n",
      "    \"https://www.goworkwize.com/blog/microsoft-intune-best-practices\",\n",
      "    \"https://www.reddit.com/r/Intune/comments/1dmozfw/compliance_policies_whats_your_approach/\"\n",
      "  ],\n",
      "  \"summary\": \"Use compliance policies to set rules for devices you manage with Intune. Conditional Access can enforce Microsoft Entra access controls based on a devices current compliance status to help ensure that only devices that are compliant are permitted to access corporate resources.\",\n",
      "  \"timestamp\": \"2025-08-01T04:50:17.424034\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "#Example usage\n",
    "#1. Check cache\n",
    "cached=get_cached_result_sqlite(query)\n",
    "if cached:\n",
    "    print(\"Loaded from cache:\")\n",
    "    print(json.dumps(cached,indent=2))\n",
    "else:\n",
    "    print(\"Fetching fresh data...\")\n",
    "    urls=search_google_serpapi(query,SERPAPI_KEY)\n",
    "    chunks=[extract_page_text(url) for url in urls]\n",
    "    top_chunks=rank_chunks_by_similarity(chunks, query)\n",
    "    summary=summarize_text_with_llm(\"\\n\\n\".join(top_chunks))\n",
    "\n",
    "    #2. Store in cache\n",
    "    store_result_in_cache_sqlite(query,urls,summary)\n",
    "    print(\"Stored in cache.\")\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (sop_env)",
   "language": "python",
   "name": "sop_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
